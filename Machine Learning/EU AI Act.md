# EU Artificial Intelligence Act

**Current Status (09-12-2023 ):** _"The agreed text will now have to be formally adopted by both Parliament  and Council to become EU law. Parliamentâ€™s Internal Market and Civil  Liberties committees will vote on the agreement in a forthcoming  meeting."_

-> [Full-Text](https://artificialintelligenceact.eu/the-act/)

The European Union is spearheading AI regulation with the world's first comprehensive AI law, the AI Act, focusing on fostering development while **trying to** ==ensure safety, transparency, and fairness==.

1. **Risk-based Regulation**: AI systems will be classified and regulated based on the risk they pose, ranging from ==unacceptable and high risk to limited risk==, with corresponding regulatory measures.
2. **Unacceptable Risk**: Certain AI systems deemed a threat to people, such as those capable of manipulative behavior modification or mass surveillance (like real-time biometric identification), will be banned, ==with some exceptions for law enforcement under strict conditions==.
3. **High Risk**: This category includes AI systems involved in critical sectors like healthcare, transportation, and law enforcement, requiring compliance with stringent EU safety standards and registration in an EU database. They will undergo assessment before and during their lifecycle.
4. **General Purpose and Generative AI**: Tools like generative AI will need to meet transparency requirements, such as disclosing AI-generated content and preventing illegal content generation. High-impact models might undergo thorough evaluations. General-purpose AI systems must adhere to transparency requirements  including technical documentation and compliance with copyright laws
5. **Limited Risk**: AI systems posing minimal risk will require minimal transparency measures to allow users to make informed decisions, particularly for AI that manipulates media content.
6. **Banned AI Applications**: Specific applications of AI are ==prohibited due to threats to citizen's rights and democracy== These  include systems that categorize individuals based on sensitive  characteristics, untargeted scraping of facial images, emotion  recognition in workplaces and educational institutions, social scoring,  manipulation of human behavior to undermine free will, and exploiting  vulnerabilities of certain groups.
7. **Sanctions**: Non-compliance with the rules can lead to fines ranging from 35 million  euro or 7% of global turnover to 7.5 million or 1.5 % of turnover,  depending on the infringement and size of the company.

## Comments

> "Because artificial intelligence systems are already subject to  comprehensive regulation today. They are software trained on databases.  And there are plenty of laws that should actually be observed. And the  AI Act might create more new permissions than prohibitions. Much that  would be forbidden under the current status may now be permissible under certain conditions with the AI regulation."

> "Because a crucial part was almost completely left out in the AI  regulation: Who actually guarantees the permissibility of use? The AI  Act only regulates this superficially; practically, not a single  question relevant to deployment is conclusively answered with it. There  are already major problems with the tokenization of content that may  have violated copyright law. The same applies to the use of personal  data from public sources."



## Open Questions

> To what extent do the statements from providers also release the  deploying company from verifying the truth of these statements?

> Are  deploying companies allowed to rely in good faith that the AI model has  been properly trained?

Can I as a user use ChatGPT in a product and not worry about the quality of the training of the model? If the modell talks fakenews and I am selling these fakenews as part of my product?

> And what does the practical implementation of the prohibition of automated decisions according to the General Data  Protection Regulation, which continues to apply even after the AI Act,  look like?

The EU AI Act is no single source of truth. Instead, it has to be considered alongside all the existing regulations like the DSGVO/GDPR.

>Who is liable in case of an incident?

A corresponding regulation/extension is due in 2025...

>Is AI deployment  insurable - and at what cost?